{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu using PyTorch 1.13.1+cpu and Flower 1.1.0\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10\n",
    "from flwr.server.strategy import FedAvg\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.common import FitRes, parameters_to_ndarrays, ndarrays_to_parameters, Metrics\n",
    "from torchvision.models._api import Weights\n",
    "\n",
    "from tinysmpc import VirtualMachine, PrivateScalar\n",
    "from tinysmpc.fixed_point import fixed_point, float_point\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
    "print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_CLIENTS = 10\n",
    "\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-10 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    # Split training set into `num_clients` partitions to simulate different local datasets\n",
    "    partition_size = len(trainset) // num_clients\n",
    "    lengths = [partition_size] * num_clients\n",
    "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for ds in datasets:\n",
    "        len_val = len(ds) // 10  # 10 % validation set\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
    "    testloader = DataLoader(testset, batch_size=32)\n",
    "    return trainloaders, valloaders, testloader\n",
    "\n",
    "\n",
    "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "\n",
    "def train(net, trainloader, epochs: int):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = criterion(net(images), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"Epoch {epoch + 1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
    "\n",
    "\n",
    "def test(net, testloader):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader):\n",
    "        self.cid = cid\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "def client_fn(cid) -> FlowerClient:\n",
    "    net = Net().to(DEVICE)\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "    return FlowerClient(cid, net, trainloader, valloader)\n",
    "\n",
    "\n",
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    print(f\"TRAINING ACCURACY: {sum(accuracies) / sum(examples)}\")\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "\n",
    "# The `evaluate` function will be by Flower called after every round\n",
    "def evaluate(\n",
    "    server_round: int, parameters: fl.common.NDArrays, config: Dict[str, fl.common.Scalar]\n",
    ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
    "    net = Net().to(DEVICE)\n",
    "    valloader = valloaders[0]\n",
    "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
    "    loss, accuracy = test(net, valloader)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flower 2023-01-25 14:32:58,537 | app.py:140 | Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n",
      "2023-01-25 14:33:00,272\tINFO worker.py:1518 -- Started a local Ray instance.\n",
      "INFO flower 2023-01-25 14:33:04,121 | app.py:174 | Flower VCE: Ray initialized with resources: {'node:127.0.0.1': 1.0, 'memory': 2740550862.0, 'object_store_memory': 1370275430.0, 'CPU': 4.0}\n",
      "INFO flower 2023-01-25 14:33:04,123 | server.py:86 | Initializing global parameters\n",
      "INFO flower 2023-01-25 14:33:04,124 | server.py:270 | Requesting initial parameters from one random client\n",
      "INFO flower 2023-01-25 14:33:08,067 | server.py:274 | Received initial parameters from one random client\n",
      "INFO flower 2023-01-25 14:33:08,069 | server.py:88 | Evaluating initial parameters\n",
      "INFO flower 2023-01-25 14:33:08,070 | server.py:101 | FL starting\n",
      "DEBUG flower 2023-01-25 14:33:08,071 | server.py:215 | fit_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_get_parameters pid=16120)\u001B[0m [Client 0] get_parameters\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=16120)\u001B[0m [Client 1] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=13940)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=16120)\u001B[0m Epoch 1: train loss 0.06511736661195755, accuracy 0.21866666666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-01-25 14:33:22,931 | server.py:229 | fit_round 1 received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=13940)\u001B[0m Epoch 1: train loss 0.06474746018648148, accuracy 0.2311111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING flower 2023-01-25 14:33:23,649 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
      "DEBUG flower 2023-01-25 14:33:23,649 | server.py:165 | evaluate_round 1: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=13940)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=16120)\u001B[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-01-25 14:33:28,605 | server.py:179 | evaluate_round 1 received 2 results and 0 failures\n",
      "WARNING flower 2023-01-25 14:33:28,606 | fedavg.py:273 | No evaluate_metrics_aggregation_fn provided\n",
      "DEBUG flower 2023-01-25 14:33:28,606 | server.py:215 | fit_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=13940)\u001B[0m [Client 0] fit, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=16120)\u001B[0m [Client 1] fit, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-01-25 14:33:39,542 | server.py:229 | fit_round 2 received 2 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_fit pid=16120)\u001B[0m Epoch 1: train loss 0.056591618806123734, accuracy 0.3391111111111111\n",
      "\u001B[2m\u001B[36m(launch_and_fit pid=13940)\u001B[0m Epoch 1: train loss 0.05710841342806816, accuracy 0.3293333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-01-25 14:33:40,215 | server.py:165 | evaluate_round 2: strategy sampled 2 clients (out of 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=16120)\u001B[0m [Client 1] evaluate, config: {}\n",
      "\u001B[2m\u001B[36m(launch_and_evaluate pid=13940)\u001B[0m [Client 0] evaluate, config: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flower 2023-01-25 14:33:45,550 | server.py:179 | evaluate_round 2 received 2 results and 0 failures\n",
      "INFO flower 2023-01-25 14:33:45,551 | server.py:144 | FL finished in 37.4795585\n",
      "INFO flower 2023-01-25 14:33:45,551 | app.py:192 | app_fit: losses_distributed [(1, 0.06267424261569976), (2, 0.05611804616451264)]\n",
      "INFO flower 2023-01-25 14:33:45,551 | app.py:193 | app_fit: metrics_distributed {}\n",
      "INFO flower 2023-01-25 14:33:45,551 | app.py:194 | app_fit: losses_centralized []\n",
      "INFO flower 2023-01-25 14:33:45,557 | app.py:195 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "History (loss, distributed):\n",
       "\tround 1: 0.06267424261569976\n",
       "\tround 2: 0.05611804616451264"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = 2657003489534545107915232808830590043\n",
    "fixedPoint = np.vectorize(fixed_point)\n",
    "floatPoint = np.vectorize(float_point)\n",
    "\n",
    "\n",
    "class FedAvgSmc(FedAvg):\n",
    "    def aggregate_fit(\n",
    "            self,\n",
    "            rnd: int,\n",
    "            results: List[Tuple[fl.server.client_proxy.ClientProxy, FitRes]],\n",
    "            failures: List[BaseException],\n",
    "    ) -> Optional[Weights]:\n",
    "        if not results:\n",
    "            return None\n",
    "\n",
    "        clients = []\n",
    "        fit_results = []\n",
    "\n",
    "        for client, fit_result in results:\n",
    "            clients.append(client)\n",
    "            fit_results.append(fit_result)\n",
    "\n",
    "        fit_res_ndarray_parameters = [parameters_to_ndarrays(result.parameters) for result in\n",
    "                                      fit_results]  # list of clients, each with a list of layers(each layer representing weights)\n",
    "\n",
    "        fl_nodes = [VirtualMachine(f\"Client: {client.cid}\") for client in clients]\n",
    "\n",
    "        num_layers = len(fit_results[0].parameters.tensors)\n",
    "\n",
    "        layers_weights = {}\n",
    "\n",
    "        layers_weights_smc = {}\n",
    "\n",
    "        for layer in range(num_layers):  #loop through number of layers\n",
    "            layers_weights[f\"layer_{layer}\"] = []\n",
    "            for weights in fit_res_ndarray_parameters:\n",
    "                layers_weights[f\"layer_{layer}\"].append(fixedPoint(weights[layer]))\n",
    "\n",
    "        for layer in range(num_layers):\n",
    "            fl_node_values = [PrivateScalar(tensor, node) for tensor, node in\n",
    "                              zip(layers_weights[f'layer_{layer}'], fl_nodes)]\n",
    "\n",
    "            fl_exchanged_shares = []\n",
    "            fl_exchanged_shares_list = []\n",
    "            layers_weights_smc[f\"layer_{layer}\"] = []\n",
    "\n",
    "            for value in fl_node_values:\n",
    "                fl_exchanged_shares.append(value.share_tensor(fl_nodes, Q))\n",
    "\n",
    "            for client_shares in fl_exchanged_shares:\n",
    "                fl_exchanged_shares_list = [share.value for share in client_shares.shares]\n",
    "\n",
    "            layers_weights_smc[f'layer_{layer}'] = floatPoint(fl_exchanged_shares_list)\n",
    "\n",
    "        # for i, client in enumerate(clients):\n",
    "        #     client_weights = []\n",
    "        #     for layer in layers_weights_smc.values():\n",
    "        #         client_weights.append(np.array(layer[i]))\n",
    "        #     fit_results[i].parameters = ndarrays_to_parameters(client_weights)\n",
    "        #\n",
    "        # results = tuple(zip(clients, fit_results))\n",
    "\n",
    "        return super().aggregate_fit(rnd, results, failures)\n",
    "\n",
    "\n",
    "strategy = FedAvgSmc(fraction_fit=0.3, fraction_evaluate=0.3, min_fit_clients=3, min_evaluate_clients=3,\n",
    "                     min_available_clients=NUM_CLIENTS, evaluate_fn=evaluate)\n",
    "fl.simulation.start_simulation(client_fn=client_fn, num_clients=2, config=fl.server.ServerConfig(num_rounds=2),\n",
    "                               strategy=FedAvgSmc(), )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
